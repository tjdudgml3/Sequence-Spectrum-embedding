{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_preprocess.py\n",
    "this code is for making dataframe using mgf file. \n",
    "dataframe will have columns of sequence, mass, spectrum begin idx, end idx ...\n",
    "\n",
    "and the rest are test code\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"/home/workplace/ms2/embedding/LIBRARY_AUGMENT-adfc8252-download_filtered_mgf_library-main.mgf\")\n",
    "content = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259456768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"all.pkl\", \"wb\") as f:\n",
    "    pickle.dump(content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all.pkl\", \"rb\") as f1:\n",
    "    list1 = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,a in enumerate(content):\n",
    "    if i < 5568:\n",
    "        print(a)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_index = []\n",
    "end_idx = []\n",
    "sequence = []\n",
    "charge = []\n",
    "pepmass = []\n",
    "scan = []\n",
    "score = []\n",
    "fdr = []\n",
    "protein = []\n",
    "for i,line in enumerate(content):\n",
    "    if line == \"BEGIN IONS\\n\":\n",
    "        begin_index.append(i)\n",
    "    elif line == \"END IONS\\n\":\n",
    "        end_idx.append(i)\n",
    "    elif \"PEPMASS\" in line:\n",
    "        pepmass.append(line[8:-1])\n",
    "    elif \"CHARGE\" in line:\n",
    "        charge.append(line[7:-1])\n",
    "    elif \"SCANS\" in line:\n",
    "        scan.append(line[6:-1])\n",
    "    elif \"SEQ\" in line:\n",
    "        sequence.append(line[4:-1])\n",
    "    elif \"SCORE\" in line:\n",
    "        score.append(line[6:-1])\n",
    "    elif \"FDR\" in line:\n",
    "        fdr.append(line[4:-1])\n",
    "    elif \"PROTEIN\" in line:\n",
    "        protein.append(line[8:-1])\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"begin_index\" : begin_index,\n",
    "                   \"end_idx\" : end_idx,\n",
    "                   \"pepmass\" : pepmass,\n",
    "                   \"charge\" : charge,\n",
    "                   \"scan\" : scan,\n",
    "                   \"sequence\" : sequence,\n",
    "                   \"score\" : score,\n",
    "                   \"fdr\" : fdr,\n",
    "                   \"protein\" : protein})\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_processed.tsv\", sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_processed.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140865, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[df.loc[0, \"begin_index\"]+16:df.loc[0, \"end_idx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum(mgf, begin, end):\n",
    "    spectrum = mgf[begin + 16: end]\n",
    "    mz = [float(i.split(\"\\t\")[0].strip()) for i in spectrum]\n",
    "    intensity = [float(i.split(\"\\t\")[1].strip()) for i in spectrum]\n",
    "    mz = np.array(mz)\n",
    "    intensity = np.array(intensity)\n",
    "    return mz, intensity\n",
    "\n",
    "@nb.njit\n",
    "def _norm_intensity(spectrum_intensity: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize spectrum peak intensities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum_intensity : np.ndarray\n",
    "        The spectrum peak intensities to be normalized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The normalized peak intensities.\n",
    "    \"\"\"\n",
    "    return spectrum_intensity / np.linalg.norm(spectrum_intensity)\n",
    "\n",
    "\n",
    "print(get_spectrum(content, 0,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz, intensity = get_spectrum(content, 0, 42)\n",
    "print(intensity)\n",
    "\n",
    "intensity_norm = _norm_intensity(intensity)\n",
    "print(intensity_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum_utils.spectrum import MsmsSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = MsmsSpectrum(\"123\",precursor_mz=1020,precursor_charge=2, mz=mz, intensity=intensity_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_num_bins(min_mz: float, max_mz: float, bin_size: float) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of bins over the given mass range for the given bin\n",
    "    size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_mz : float\n",
    "        The minimum m/z to include in the vector.\n",
    "    max_mz : float\n",
    "        The maximum m/z to include in the vector.\n",
    "    bin_size : float\n",
    "        The bin size in m/z used to divide the m/z range.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of bins over the given mass range for the given bin size.\n",
    "    \"\"\"\n",
    "    return math.ceil((max_mz - min_mz) / bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_num_bins(50.5,2500,1.0005079))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "def to_vector(spectrum_mz: np.ndarray, spectrum_intensity: np.ndarray,\n",
    "              min_mz: float, bin_size: float, num_bins: int)\\\n",
    "        -> ss.csr_matrix:\n",
    "    \"\"\"\n",
    "    Convert the given spectrum to a binned sparse SciPy vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum_mz : np.ndarray\n",
    "        The peak m/z values of the spectrum to be converted to a vector.\n",
    "    spectrum_intensity : np.ndarray\n",
    "        The peak intensities of the spectrum to be converted to a vector.\n",
    "    min_mz : float\n",
    "        The minimum m/z to include in the vector.\n",
    "    bin_size : float\n",
    "        The bin size in m/z used to divide the m/z range.\n",
    "    num_bins : int\n",
    "        The number of elements of which the vector consists.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ss.csr_matrix\n",
    "        The binned spectrum vector.\n",
    "    \"\"\"\n",
    "    bins = ((spectrum_mz - min_mz) / bin_size).astype(np.int32)\n",
    "    # bins = np.append(bins,837)\n",
    "    # spectrum_intensity = np.append(spectrum_intensity,0.5)\n",
    "    # print(bins)\n",
    "    print(num_bins)\n",
    "    vector = ss.csr_matrix(\n",
    "        (spectrum_intensity, (np.repeat(0, len(spectrum_intensity)), bins)),\n",
    "        shape=(1, num_bins), dtype=np.float32)\n",
    "    return vector\n",
    "    # return vector / scipy.sparse.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = to_vector(spectrum_mz=spectrum.mz, spectrum_intensity=spectrum.intensity, min_mz=50.5, bin_size=1.0005079, num_bins=2449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in vector:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum.mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_LIST = [['-', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'] ,]\n",
    "MAX_LEN= 125\n",
    "# AA_LIST = np.reshape(AA_LIST,(-1,1))\n",
    "# AA_LIST = list(AA_LIST)\n",
    "# AA_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'MDR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_pad = seq[:MAX_LEN] if len(seq) > MAX_LEN else seq + '-' * (MAX_LEN - len(seq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df = pd.DataFrame([{'aa': x} for i, x in enumerate(seq_pad)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "seq_ohe = sklearn.preprocessing.OneHotEncoder(categories=AA_LIST).fit_transform(seq_df)\n",
    "# .fit_transform(seq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_spectrum_valid(spectrum_mz: np.ndarray, min_peaks: int,\n",
    "                          min_mz_range: float) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether a spectrum is of high enough quality to be used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum_mz : np.ndarray\n",
    "        M/z peaks of the sspectrum whose quality is checked.\n",
    "    min_peaks : int\n",
    "        Minimum number of peaks a spectrum has to contain.\n",
    "    min_mz_range : float\n",
    "        Minimum m/z range the spectrum's peaks need to cover.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the spectrum has enough peaks covering a wide enough mass\n",
    "        range, False otherwise.\n",
    "    \"\"\"\n",
    "    return (len(spectrum_mz) >= min_peaks and\n",
    "            spectrum_mz[-1] - spectrum_mz[0] >= min_mz_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def preprocess(spectrum: MsmsSpectrum,\n",
    "               mz_min: float,\n",
    "               mz_max: float,\n",
    "               min_peaks: int,\n",
    "               min_mz_range: float,\n",
    "               remove_precursor_tolerance: Optional[float],\n",
    "               min_intensity: float,\n",
    "               max_peaks_used: int,\n",
    "               scaling: Optional[str]) -> MsmsSpectrum:\n",
    "    \"\"\"\n",
    "    Preprocess the given spectrum.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrum:  MsmsSpectrum\n",
    "        The spectrum to be preprocessed.\n",
    "    mz_min : float\n",
    "        The minimum m/z value to be included.\n",
    "    mz_max : float\n",
    "        The maximum m/z value to be included.\n",
    "    min_peaks : int\n",
    "        Minimum number of peaks the spectrum needs to have to be considered\n",
    "        valid.\n",
    "    min_mz_range : float\n",
    "        Minimum m/z range to be covered for the spectrum to be considered\n",
    "        valid.\n",
    "    remove_precursor_tolerance : Optional[float]\n",
    "        Remove peaks within the given m/z of the precursor peak.\n",
    "    min_intensity : float\n",
    "        Discard peaks below the given minimum intensity.\n",
    "    max_peaks_used : int\n",
    "        Retain only the given number of most intense peaks.\n",
    "    scaling : Optional[str]\n",
    "        Perform optional intensity scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The normalized peak intensities.\n",
    "    \"\"\"\n",
    "    if spectrum.is_processed:\n",
    "        return spectrum\n",
    "\n",
    "    spectrum = spectrum.set_mz_range(mz_min, mz_max)\n",
    "    if not _check_spectrum_valid(spectrum.mz, min_peaks, min_mz_range):\n",
    "        spectrum.is_valid = False\n",
    "        spectrum.is_processed = True\n",
    "        return spectrum\n",
    "\n",
    "    if remove_precursor_tolerance is not None:\n",
    "        spectrum = spectrum.remove_precursor_peak(\n",
    "            remove_precursor_tolerance, 'Da')\n",
    "        if not _check_spectrum_valid(spectrum.mz, min_peaks, min_mz_range):\n",
    "            spectrum.is_valid = False\n",
    "            spectrum.is_processed = True\n",
    "            return spectrum\n",
    "\n",
    "    spectrum = spectrum.filter_intensity(min_intensity, max_peaks_used)\n",
    "    if not _check_spectrum_valid(spectrum.mz, min_peaks, min_mz_range):\n",
    "        spectrum.is_valid = False\n",
    "        spectrum.is_processed = True\n",
    "        return spectrum\n",
    "\n",
    "    scaling = scaling\n",
    "    if scaling == 'sqrt':\n",
    "        scaling = 'root'\n",
    "    if scaling is not None:\n",
    "        spectrum = spectrum.scale_intensity(scaling, max_rank=max_peaks_used)\n",
    "    print(spectrum.intensity)\n",
    "    # spectrum.intensity = _norm_intensity(spectrum.intensity)\n",
    "    inten = _norm_intensity(spectrum.intensity)\n",
    "    # Set a flag to indicate that the spectrum has been processed to avoid\n",
    "    # reprocessing.\n",
    "    spectrum.intensity = inten\n",
    "    spectrum.is_valid = True\n",
    "    spectrum.is_processed = True\n",
    "\n",
    "    return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = preprocess(spectrum=spectrum, mz_min=50.5, mz_max=2500, min_mz_range=10,min_peaks=20, remove_precursor_tolerance=0.5, min_intensity=0.1, max_peaks_used=50, scaling='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum.mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum._intensity = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = to_vector(spectrum.mz, spectrum.intensity, min_mz=50.5, bin_size=1.0005079, num_bins=2449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in vector1:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class Dataloader(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle=False):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "\t\t# batch 단위로 직접 묶어줘야 함\n",
    "    def __getitem__(self, idx):\n",
    "\t\t\t\t# sampler의 역할(index를 batch_size만큼 sampling해줌)\n",
    "        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        batch_x = [self.x[i] for i in indices]\n",
    "        batch_y = [self.y[i] for i in indices]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # epoch이 끝날때마다 실행\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "\n",
    "# train_loader = Dataloader(x, y, 128, shuffle=True)\n",
    "# valid_loader = Dataloader(x, y, 128)\n",
    "# test_loader = Dataloader(x, y, 128)\n",
    "\n",
    "# 방법 1\n",
    "# model.fit(train_loader, validation_data=valid_loader, epochs=10,\n",
    "# \t\t\t\t\tworkers=4)# multi로 처리할 개수\n",
    "# model.evaluate(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.utils.data_utils.Sequence"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
