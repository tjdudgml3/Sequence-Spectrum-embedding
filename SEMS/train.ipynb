{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build model. \n",
    "\n",
    "tarin model \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_process import preprocess, to_vector\n",
    "# from data_generator import PairSequence\n",
    "from spectrum_utils.spectrum import MsmsSpectrum\n",
    "import sklearn.preprocessing\n",
    "import re\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import data_generator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.layers import concatenate, Conv1D, Dense, Flatten, \\\n",
    "    Lambda, MaxPooling1D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.optimizers import RectifiedAdam, AdamW\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/home/workplace/ms2/embedding/LIBRARY_AUGMENT-adfc8252-download_filtered_mgf_library-main.mgf\")\n",
    "mgf = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_pairs = pd.read_csv(\"negative_pair.tsv\", delimiter=\"\\t\")\n",
    "# positive_pairs = pd.read_csv(\"positive_pair.tsv\", delimiter=\"\\t\")\n",
    "# negative_pairs = negative_pairs[:100000]\n",
    "# positive_pairs = positive_pairs[:10000]\n",
    "test_pos = pd.read_csv(\"test_pos_12_11.tsv\", delimiter=\"\\t\")\n",
    "test_neg = pd.read_csv(\"test_neg_12_11.tsv\", delimiter=\"\\t\")\n",
    "train_pos = pd.read_csv(\"train_pos_12_11.tsv\", delimiter=\"\\t\")\n",
    "train_neg = pd.read_csv(\"train_neg_12_11.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "#change this code for test\n",
    "test_pos = pd.read_csv(\"dataset/test_pos.tsv\", delimiter=\"\\t\")\n",
    "test_neg = pd.read_csv(\"dataset/test_neg.tsv\", delimiter=\"\\t\")\n",
    "train_pos = pd.read_csv(\"dataset/train_pos.tsv\", delimiter=\"\\t\")\n",
    "train_neg = pd.read_csv(\"dataset/train_neg.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_pairs = negative_pairs.sample(frac=1).reset_index(drop=True)\n",
    "# positive_pairs = positive_pairs.sample(frac=1).reset_index(drop=True)\n",
    "# test_neg = negative_pairs[:negative_pairs.shape[0]//4]\n",
    "# train_neg = negative_pairs[negative_pairs.shape[0]//4:].reset_index(drop=True)\n",
    "\n",
    "# test_pos = positive_pairs[:positive_pairs.shape[0]//4]\n",
    "# train_pos = positive_pairs[positive_pairs.shape[0]//4:].reset_index(drop=True)\n",
    "\n",
    "# test_neg.to_csv(\"test_neg_12_11.tsv\", sep=\"\\t\", index=False)\n",
    "# train_neg.to_csv(\"train_neg_12_11.tsv\", sep=\"\\t\", index=False)\n",
    "# test_pos.to_csv(\"test_pos_12_11.tsv\", sep=\"\\t\", index=False)\n",
    "# train_pos.to_csv(\"train_pos_12_11.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>spec_sequence</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>pepmass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDPNFLLK</td>\n",
       "      <td>LLVDMDPR</td>\n",
       "      <td>58795662</td>\n",
       "      <td>58795698</td>\n",
       "      <td>479.756946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IIQEPPHKK</td>\n",
       "      <td>C+57.021ADDRADLAK</td>\n",
       "      <td>231461791</td>\n",
       "      <td>231461912</td>\n",
       "      <td>568.291748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LYLGSGYFTAIQNLR</td>\n",
       "      <td>TELYQSLADLNNVR</td>\n",
       "      <td>59519854</td>\n",
       "      <td>59520155</td>\n",
       "      <td>818.422485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QAQELSWEK</td>\n",
       "      <td>YWVSPSPAK</td>\n",
       "      <td>215278600</td>\n",
       "      <td>215278655</td>\n",
       "      <td>517.770121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIAASGHFIC+57.021VGTWSGR</td>\n",
       "      <td>MAPVPLDDSNRPASLTK</td>\n",
       "      <td>32871811</td>\n",
       "      <td>32871935</td>\n",
       "      <td>906.468550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781380</th>\n",
       "      <td>MAANLYAR</td>\n",
       "      <td>VHGSPLELK</td>\n",
       "      <td>147770205</td>\n",
       "      <td>147770344</td>\n",
       "      <td>490.282386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781381</th>\n",
       "      <td>ALDQYLMEFNAC+57.021R</td>\n",
       "      <td>LKYPSSPYSAHISK</td>\n",
       "      <td>188346860</td>\n",
       "      <td>188346888</td>\n",
       "      <td>789.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781382</th>\n",
       "      <td>MGSPAPLLPGDLLGGGSDSI</td>\n",
       "      <td>FIQVC+57.021TQLQVLTEAFR</td>\n",
       "      <td>71115857</td>\n",
       "      <td>71116054</td>\n",
       "      <td>977.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781383</th>\n",
       "      <td>C+57.021PAESVDSSGK</td>\n",
       "      <td>YLGAMQVADK</td>\n",
       "      <td>129830734</td>\n",
       "      <td>129830902</td>\n",
       "      <td>548.278869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781384</th>\n",
       "      <td>VPHIPFDFYLC+57.021EMAFPR</td>\n",
       "      <td>PLSVELGPGIMGAIFDGIQR</td>\n",
       "      <td>183473224</td>\n",
       "      <td>183473388</td>\n",
       "      <td>1035.556136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4781385 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sequence            spec_sequence      begin  \\\n",
       "0                        LDPNFLLK                 LLVDMDPR   58795662   \n",
       "1                       IIQEPPHKK        C+57.021ADDRADLAK  231461791   \n",
       "2                 LYLGSGYFTAIQNLR           TELYQSLADLNNVR   59519854   \n",
       "3                       QAQELSWEK                YWVSPSPAK  215278600   \n",
       "4        GIAASGHFIC+57.021VGTWSGR        MAPVPLDDSNRPASLTK   32871811   \n",
       "...                           ...                      ...        ...   \n",
       "4781380                  MAANLYAR                VHGSPLELK  147770205   \n",
       "4781381      ALDQYLMEFNAC+57.021R           LKYPSSPYSAHISK  188346860   \n",
       "4781382      MGSPAPLLPGDLLGGGSDSI  FIQVC+57.021TQLQVLTEAFR   71115857   \n",
       "4781383        C+57.021PAESVDSSGK               YLGAMQVADK  129830734   \n",
       "4781384  VPHIPFDFYLC+57.021EMAFPR     PLSVELGPGIMGAIFDGIQR  183473224   \n",
       "\n",
       "               end      pepmass  \n",
       "0         58795698   479.756946  \n",
       "1        231461912   568.291748  \n",
       "2         59520155   818.422485  \n",
       "3        215278655   517.770121  \n",
       "4         32871935   906.468550  \n",
       "...            ...          ...  \n",
       "4781380  147770344   490.282386  \n",
       "4781381  188346888   789.420000  \n",
       "4781382   71116054   977.019612  \n",
       "4781383  129830902   548.278869  \n",
       "4781384  183473388  1035.556136  \n",
       "\n",
       "[4781385 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(xy: list[tf.Tensor]):\n",
    "    \"\"\"\n",
    "    Euclidean distance between two vectors using Keras.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xy : List[tf.Tensor]\n",
    "        List of two vectors between which to compute the Euclidean distance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The Euclidean distance between the two given vectors.\n",
    "    \"\"\"\n",
    "    x, y = xy\n",
    "    # sumsquare = x+y\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "    # return sumsquare\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    \"\"\"\n",
    "    Get the shape of the Euclidean distance output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shapes\n",
    "        Input shapes to the Euclidean distance calculation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The shape of the Euclidean distance output.\n",
    "    \"\"\"\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1[0], 1\n",
    "\n",
    "def contrastive_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Contrastive loss function adapted from Hadsell et al. 2006.\n",
    "    (http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)\n",
    "\n",
    "    The contrastive loss is modified so that it takes a certainty that labels\n",
    "    are correct into account. This helps the neural network to overcome\n",
    "    incorrectly labeled instances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf.Tensor\n",
    "        The true class labels.\n",
    "    y_pred : tf.Tensor\n",
    "        The predicted embedded Euclidean distances.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The contrastive loss between the true and predicted class labels.\n",
    "    \"\"\"\n",
    "    ramp_square = K.square(K.minimum(y_pred, 1))\n",
    "    # ramp_square = K.log(y_pred)\n",
    "    # margin_square = K.log(1-y_pred)\n",
    "    margin_square = K.square(K.maximum(1 - y_pred, 0))\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return K.mean(y_true * 0.99 * ramp_square +\n",
    "                  (1 - y_true * 0.99) * margin_square)\n",
    "    \n",
    "    \n",
    "# def contrastive_loss(y_true:tf.Tensor, y_pred : tf.Tensor):\n",
    "#     pass\n",
    "\n",
    "def similarity(xy: list[tf.Tensor]):\n",
    "    x, y = xy\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, num_fragment_features : int =2449, num_seq_features : int = 50, lr : float=0.01, filename : str = 'embedder.hdf5'):\n",
    "        self.num_fragment_features = num_fragment_features\n",
    "        self.num_seq_features = num_seq_features \n",
    "        self.filename = filename\n",
    "        self.model = None\n",
    "        self.lr = lr\n",
    "        \n",
    "    \n",
    "    def build_fragment_embedder_model(self)->Model:\n",
    "        filters = 30\n",
    "        kernel_size = 3\n",
    "        strides = 1\n",
    "        pool_size = 1\n",
    "        pool_strides = 2\n",
    "        \n",
    "        # seq_input = Input((self.num_seq_features, ), name='input_seq')\n",
    "        # seq_dense32 = Dense(32, activation = 'selu', kernel_initializer='lecun_normal', name='seq_dense_32')(seq_input)\n",
    "        # seq_dense200 = Dense(200, activation='selu', kernel_initializer='lecun_normal', name='seq_dense_200')(seq_dense32)\n",
    "        \n",
    "        \n",
    "        fragment_input = Input((self.num_fragment_features,), name = 'input_fragment')\n",
    "        fragment_input_reshape = Reshape((self.num_fragment_features,1), name = 'fragment_input_reshape')(fragment_input)\n",
    "        fragment_layer = fragment_input_reshape\n",
    "        \n",
    "        fragment_layer = Conv1D(filters,kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block1_conv1')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters,kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block1_conv2')(fragment_layer)\n",
    "        fragment_layer = MaxPooling1D(pool_size, pool_strides, name='fragment_block1_pool1')(fragment_layer)\n",
    "        \n",
    "        #block2\n",
    "        fragment_layer = Conv1D(filters*2, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block2_conv1')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*2, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block2_conv2')(fragment_layer)\n",
    "        fragment_layer = MaxPooling1D(pool_size, pool_strides, name='fragment_block2_pool1')(fragment_layer)\n",
    "        \n",
    "        #block3\n",
    "        fragment_layer = Conv1D(filters*4, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block3_conv1')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*4, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block3_conv2')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*4, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block3_conv3')(fragment_layer)\n",
    "        fragment_layer = MaxPooling1D(pool_size, pool_strides, name='fragment_block3_pool1')(fragment_layer)\n",
    "        \n",
    "        #block4\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block4_conv1')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block4_conv2')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block4_conv3')(fragment_layer)\n",
    "        fragment_layer = MaxPooling1D(pool_size, pool_strides, name='fragment_block4_pool1')(fragment_layer)\n",
    "        \n",
    "        #block5\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block5_conv1')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block5_conv2')(fragment_layer)\n",
    "        fragment_layer = Conv1D(filters*8, kernel_size, strides=strides, activation = 'selu', name = 'fragment_layer_block5_conv3')(fragment_layer)\n",
    "        fragment_layer = MaxPooling1D(pool_size, pool_strides, name='fragment_block5_pool1')(fragment_layer)\n",
    "        \n",
    "        fragment_output = Flatten(name='fragment_flatten')(fragment_layer)\n",
    "        \n",
    "        fragment_output = Dense(200, activation = 'selu', kernel_initializer = 'lecun_normal', activity_regularizer='l2', name='output')(fragment_output)\n",
    "        \n",
    "        return Model(inputs = [fragment_input], outputs = [fragment_output], name = 'frag_embedder')\n",
    "     \n",
    "    def build_seq_embedder_model(self)->Model:\n",
    "        \n",
    "        seq_input = Input((self.num_seq_features, 21, ), name='input_seq')\n",
    "        seq_dense32 = Dense(32, activation = 'selu', kernel_initializer='lecun_normal', name='seq_dense_32')(seq_input)\n",
    "        seq_flatten = Flatten(name='seq_flatten')(seq_dense32)\n",
    "        seq_dense200 = Dense(200, activation='selu', kernel_initializer='lecun_normal', name='seq_dense_200')(seq_flatten)\n",
    "        \n",
    "        return Model(inputs = [seq_input], outputs = [seq_dense200], name = 'seq_embedder')\n",
    "\n",
    "    \n",
    "    def build_model(self)->None:\n",
    "        fragment_embedder_model = self.build_fragment_embedder_model()\n",
    "        input_ms2 = [Input((self.num_fragment_features,),name='input_ms2_fragment')]\n",
    "        output_ms2 = fragment_embedder_model(input_ms2)\n",
    "        \n",
    "        seq_embedder_model = self.build_seq_embedder_model()\n",
    "        input_seq =  [Input((self.num_seq_features,21,),name='input_seq')]\n",
    "        output_seq = seq_embedder_model(input_seq)\n",
    "        # distance = (Lambda(euclidean_distance, eucl_dist_output_shape,\n",
    "        #                    name='embedding_euclidean_distance')\n",
    "        #             ([output_ms2, output_seq]))\n",
    "        \n",
    "        distance = (Lambda(similarity, eucl_dist_output_shape,\n",
    "                           name='embedding_similarity')\n",
    "                    ([output_ms2, output_seq]))\n",
    "        \n",
    "        #print(f\"fragmnet input shape = {input_ms2} seq_input shape = {input_seq} \")\n",
    "        \n",
    "\n",
    "        return Model(inputs=[input_ms2, input_seq], outputs=distance,\n",
    "                     name='base_model')\n",
    "        # distance = (Lambda(euclidean_distance, eucl_dist_output_shape,\n",
    "        #                    name='embedding_euclidean_distance')\n",
    "        #             ([output_ms2, output_seq]))\n",
    "\n",
    "        # return Model(inputs=[*input_ms2, *input_seq], outputs=distance,\n",
    "        #              name='base_model')\n",
    "        # dot_product = tf.tensordot(output_ms2, output_seq, 1)\n",
    "        # pass\n",
    "    \n",
    "    def build(self) -> None:\n",
    "        \"\"\"\n",
    "        Build the Siamese model and compile it to optimize the contrastive loss\n",
    "        using Adam.\n",
    "\n",
    "        Both arms of the Siamese network will use the same embedder model, i.e.\n",
    "        the weights are tied between both arms.\n",
    "\n",
    "        The model will be parallelized over all available GPUs if applicable.\n",
    "        \"\"\"\n",
    "        # Both arms of the Siamese network use the same model,\n",
    "        # i.e. the weights are tied.\n",
    "        # strategy = tf.distribute.MirroredStrategy()\n",
    "        # with strategy.scope():\n",
    "        #     self.model = self.build_model()\n",
    "            # Train using Adam to optimize the contrastive loss.\n",
    "            # self.model.compile(RectifiedAdam(self.lr),\n",
    "            #                            contrastive_loss,\n",
    "            #                            metrics=[keras.metrics.Accuracy()])\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "        def custom_acc(y_true, y_pred):\n",
    "            threshold = 5\n",
    "            differnece = tf.abs(tf.subtract(y_true, y_pred)) - threshold\n",
    "            boolean_results = tf.where(differnece>0, True, False)\n",
    "            return K.mean(math_ops.cast(boolean_results, K.floatx()))\n",
    "                        \n",
    "        acc = tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.02)\n",
    "        \n",
    "        # self.model.compile(AdamW(self.lr),\n",
    "        #                                contrastive_loss,\n",
    "        #                                metrics=[acc])\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(\n",
    "            from_logits=True,\n",
    "            label_smoothing=0.0,\n",
    "            axis=-1,\n",
    "            name='binary_crossentropy'\n",
    "        )\n",
    "        self.model.compile(AdamW(self.lr),loss)\n",
    "        \n",
    "        \n",
    "    def train(self, train_data, validation_data):\n",
    "        filename_log = 'history.log'\n",
    "        callbacks = [ModelCheckpoint('log' + '.epoch{epoch:03d}'),\n",
    "                     CSVLogger(filename_log)]\n",
    "        # self.model.fit(\n",
    "        #     train_data,train_target,\n",
    "        #     epochs=10, batch_size = 64,\n",
    "        #     validation_data=(validation_data,validation_target),callbacks=callbacks)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./cp.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        \n",
    "        self.model.fit(\n",
    "            train_data,\n",
    "            epochs=5,\n",
    "            validation_data=(validation_data),\n",
    "            callbacks=[cp_callback])\n",
    "    # def train(self, train_generator: data_generator.PairSequence,\n",
    "    #           steps_per_epoch: int = None, num_epochs: int = 1,\n",
    "    #           validators: list[data_generator.PairSequence] = None) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Train the Siamese model.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------                                                                          \n",
    "    #     train_generator : data_generator.PairSequence\n",
    "    #         The training data generator.\n",
    "    #     steps_per_epoch : int\n",
    "    #          Total number of in each epoch. Useful to record the validation\n",
    "    #          loss at specific intervals.\n",
    "    #     num_epochs : int\n",
    "    #         The number of epochs for which training occurs.\n",
    "    #     validators : List[data_generator.PairSequence]\n",
    "    #         The validation data generators.\n",
    "    #     \"\"\"\n",
    "    #     if self.model is None:\n",
    "    #         raise ValueError(\"The Siamese model hasn't been constructed yet\")\n",
    "\n",
    "    #     # filename, ext = os.path.splitext(self.filename)\n",
    "    #     filename_log = 'history.log'\n",
    "    #     callbacks = [ModelCheckpoint('log' + '.epoch{epoch:03d}'),\n",
    "    #                  ValidationCallback(validators, filename_log),\n",
    "    #                  CSVLogger(filename_log)]\n",
    "    #     self.model.fit(\n",
    "    #         train_generator, steps_per_epoch=steps_per_epoch,\n",
    "    #         epochs=num_epochs, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ms2_fragment (InputL  [(None, 2449)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_seq (InputLayer)      [(None, 50, 21)]             0         []                            \n",
      "                                                                                                  \n",
      " frag_embedder (Functional)  (None, 200)                  4487570   ['input_ms2_fragment[0][0]']  \n",
      "                                                                                                  \n",
      " seq_embedder (Functional)   (None, 200)                  320904    ['input_seq[0][0]']           \n",
      "                                                                                                  \n",
      " embedding_similarity (Lamb  (None, 1)                    0         ['frag_embedder[0][0]',       \n",
      " da)                                                                 'seq_embedder[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4808474 (18.34 MB)\n",
      "Trainable params: 4808474 (18.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb = Embedder()\n",
    "emb.build()\n",
    "emb.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11663"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = data_generator.gen(file_name_pos=train_pos, file_name_neg=train_neg, batch_size=256, mgf=mgf)\n",
    "test_generator = data_generator.gen(file_name_pos=test_pos, file_name_neg=test_neg, batch_size=256, mgf=mgf)\n",
    "\n",
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2985728"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator) * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for a in train_generator:\n",
    "#     print((type(a[0])))\n",
    "#     print(len(a[0][0]))\n",
    "#     print(len(a[0][1]))\n",
    "#     print(len(a[1]))\n",
    "#     print(len(a[2]))\n",
    "#     print(\"               \")\n",
    "#     # print(a[2])\n",
    "#     pos = 0\n",
    "#     neg = 0\n",
    "#     for i,j in zip(a[2][0], a[2][1]):\n",
    "#         if i == j:\n",
    "#             pos += 1\n",
    "#         else:\n",
    "#             neg += 1\n",
    "#     print(f\"pos = {pos}\")\n",
    "#     print(f\"neg = {neg}\")\n",
    "#     # print(a[1].shape)\n",
    "#     # print(a[2].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11663/11663 [==============================] - ETA: 0s - loss: 0.7036\n",
      "Epoch 1: saving model to ./cp.ckpt\n",
      "11663/11663 [==============================] - 14350s 1s/step - loss: 0.7036 - val_loss: 0.6912\n",
      "Epoch 2/5\n",
      "11663/11663 [==============================] - ETA: 0s - loss: 0.6912\n",
      "Epoch 2: saving model to ./cp.ckpt\n",
      "11663/11663 [==============================] - 14250s 1s/step - loss: 0.6912 - val_loss: 0.6912\n",
      "Epoch 3/5\n",
      "11663/11663 [==============================] - ETA: 0s - loss: 0.6912\n",
      "Epoch 3: saving model to ./cp.ckpt\n",
      "11663/11663 [==============================] - 14288s 1s/step - loss: 0.6912 - val_loss: 0.6912\n",
      "Epoch 4/5\n",
      "11663/11663 [==============================] - ETA: 0s - loss: 0.6912\n",
      "Epoch 4: saving model to ./cp.ckpt\n",
      "11663/11663 [==============================] - 14263s 1s/step - loss: 0.6912 - val_loss: 0.6912\n",
      "Epoch 5/5\n",
      "11663/11663 [==============================] - ETA: 0s - loss: 0.6912\n",
      "Epoch 5: saving model to ./cp.ckpt\n",
      "11663/11663 [==============================] - 14289s 1s/step - loss: 0.6912 - val_loss: 0.6912\n"
     ]
    }
   ],
   "source": [
    "emb.train(train_generator, test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ms2_fragment (InputL  [(None, 2449)]               0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " input_seq (InputLayer)      [(None, 50, 21)]             0         []                            \n",
      "                                                                                                  \n",
      " frag_embedder (Functional)  (None, 200)                  4487570   ['input_ms2_fragment[0][0]']  \n",
      "                                                                                                  \n",
      " seq_embedder (Functional)   (None, 200)                  320904    ['input_seq[0][0]']           \n",
      "                                                                                                  \n",
      " embedding_similarity (Lamb  (None, 1)                    0         ['frag_embedder[0][0]',       \n",
      " da)                                                                 'seq_embedder[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4808474 (18.34 MB)\n",
      "Trainable params: 4808474 (18.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workplace/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "emb.model.save(\"model3_12_12.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_processed.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_index</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>pepmass</th>\n",
       "      <th>charge</th>\n",
       "      <th>scan</th>\n",
       "      <th>sequence</th>\n",
       "      <th>score</th>\n",
       "      <th>fdr</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>652.337341</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>+42.011AAAAAAALQAKSDEKAAVAGK</td>\n",
       "      <td>0.844429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|P36578|RL4_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>106</td>\n",
       "      <td>1278.664673</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>+42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR</td>\n",
       "      <td>19.629346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q92922|SMRC1_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>174</td>\n",
       "      <td>852.779275</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>+42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR</td>\n",
       "      <td>24.510680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q92922|SMRC1_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176</td>\n",
       "      <td>240</td>\n",
       "      <td>639.830340</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>+42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR</td>\n",
       "      <td>8.557637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q92922|SMRC1_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242</td>\n",
       "      <td>353</td>\n",
       "      <td>953.960000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>+42.011AAAAVGAGHGAGGPGAASSSGGAR</td>\n",
       "      <td>19.697894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q96K37|S35E1_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140860</th>\n",
       "      <td>259456258</td>\n",
       "      <td>259456318</td>\n",
       "      <td>839.410000</td>\n",
       "      <td>3</td>\n",
       "      <td>2140861</td>\n",
       "      <td>YYSSPQDLPYPDPAIAQFSVQK</td>\n",
       "      <td>7.900134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|P34932|HSP74_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140861</th>\n",
       "      <td>259456320</td>\n",
       "      <td>259456401</td>\n",
       "      <td>922.898987</td>\n",
       "      <td>2</td>\n",
       "      <td>2140862</td>\n",
       "      <td>YYTSASGDEM+15.995VSLKDY</td>\n",
       "      <td>6.935526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|P07900|HS90A_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140862</th>\n",
       "      <td>259456403</td>\n",
       "      <td>259456490</td>\n",
       "      <td>883.424510</td>\n",
       "      <td>2</td>\n",
       "      <td>2140863</td>\n",
       "      <td>YYVLLHDVSAGDEQ+0.984R</td>\n",
       "      <td>9.998685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q9Y2L5|TPPC8_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140863</th>\n",
       "      <td>259456492</td>\n",
       "      <td>259456701</td>\n",
       "      <td>589.285732</td>\n",
       "      <td>3</td>\n",
       "      <td>2140864</td>\n",
       "      <td>YYVLLHDVSAGDEQ+0.984R</td>\n",
       "      <td>9.824301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q9Y2L5|TPPC8_HUMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140864</th>\n",
       "      <td>259456703</td>\n",
       "      <td>259456766</td>\n",
       "      <td>597.813782</td>\n",
       "      <td>2</td>\n",
       "      <td>2140865</td>\n",
       "      <td>YYVVHEEKK</td>\n",
       "      <td>3.714694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sp|Q7Z6L1|TCPR1_HUMAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140865 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         begin_index    end_idx      pepmass  charge     scan  \\\n",
       "0                  0         42   652.337341       3        1   \n",
       "1                 44        106  1278.664673       2        2   \n",
       "2                108        174   852.779275       3        3   \n",
       "3                176        240   639.830340       4        4   \n",
       "4                242        353   953.960000       2        5   \n",
       "...              ...        ...          ...     ...      ...   \n",
       "2140860    259456258  259456318   839.410000       3  2140861   \n",
       "2140861    259456320  259456401   922.898987       2  2140862   \n",
       "2140862    259456403  259456490   883.424510       2  2140863   \n",
       "2140863    259456492  259456701   589.285732       3  2140864   \n",
       "2140864    259456703  259456766   597.813782       2  2140865   \n",
       "\n",
       "                                       sequence      score  fdr  \\\n",
       "0                  +42.011AAAAAAALQAKSDEKAAVAGK   0.844429  0.0   \n",
       "1        +42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR  19.629346  0.0   \n",
       "2        +42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR  24.510680  0.0   \n",
       "3        +42.011AAAAGGGGPGTAVGATGSGIAAAAAGLAVYR   8.557637  0.0   \n",
       "4               +42.011AAAAVGAGHGAGGPGAASSSGGAR  19.697894  0.0   \n",
       "...                                         ...        ...  ...   \n",
       "2140860                  YYSSPQDLPYPDPAIAQFSVQK   7.900134  0.0   \n",
       "2140861                 YYTSASGDEM+15.995VSLKDY   6.935526  0.0   \n",
       "2140862                   YYVLLHDVSAGDEQ+0.984R   9.998685  0.0   \n",
       "2140863                   YYVLLHDVSAGDEQ+0.984R   9.824301  0.0   \n",
       "2140864                               YYVVHEEKK   3.714694  0.0   \n",
       "\n",
       "                       protein  \n",
       "0          sp|P36578|RL4_HUMAN  \n",
       "1        sp|Q92922|SMRC1_HUMAN  \n",
       "2        sp|Q92922|SMRC1_HUMAN  \n",
       "3        sp|Q92922|SMRC1_HUMAN  \n",
       "4        sp|Q96K37|S35E1_HUMAN  \n",
       "...                        ...  \n",
       "2140860  sp|P34932|HSP74_HUMAN  \n",
       "2140861  sp|P07900|HS90A_HUMAN  \n",
       "2140862  sp|Q9Y2L5|TPPC8_HUMAN  \n",
       "2140863  sp|Q9Y2L5|TPPC8_HUMAN  \n",
       "2140864  sp|Q7Z6L1|TCPR1_HUMAN  \n",
       "\n",
       "[2140865 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525929\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for a in data[\"sequence\"]:\n",
    "    for b in a:\n",
    "        if b ==\"C\":\n",
    "            cnt += 1\n",
    "            \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525929\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for a in data[\"sequence\"]:\n",
    "    for b in range(len(a)):\n",
    "        if a[b] ==\"C\":\n",
    "            if a[b+1] == \"+\":\n",
    "                cnt += 1\n",
    "            \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model3_11_27.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/workplace/ms2/embedding/train.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/workplace/ms2/embedding/train.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mmodel3_11_27.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at model3_11_27.h5"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model3_11_27.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
